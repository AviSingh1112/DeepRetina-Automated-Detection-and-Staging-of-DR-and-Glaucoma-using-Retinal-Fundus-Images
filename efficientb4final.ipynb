{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==========================================================\n# Full end-to-end clean mini-training script (copy-paste)\n# ==========================================================\n\n# Imports\nimport os\nimport math\nimport random\nimport hashlib\nfrom pathlib import Path\nfrom collections import defaultdict\nimport numpy as np\nimport cv2\nfrom PIL import Image\nimport imagehash\nimport albumentations as A\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import EfficientNetB4\n\n# -------------------------\n# Config\n# -------------------------\nDATA_DIR = \"/kaggle/input/eye-diseases-classification/dataset\"\nOUTPUT_DIR = \"/kaggle/working\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(os.path.join(OUTPUT_DIR, \"artifacts\"), exist_ok=True)\n\n# Seeds\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# Sizes / training control\nIMG_SIZE = (380, 380)\nBATCH_SIZE = 16\nWARMUP_EPOCHS = 5  # as requested (doubled)\nTOTAL_EPOCHS = 80  # as requested (doubled)\nINITIAL_LR = 3e-4\nWEIGHT_DECAY = 1e-5\nPATIENCE_ES = 12\nPATIENCE_RLR = 6\n\n# Features toggles (kept same as original)\nUSE_IMAGENET = True\nUSE_CLAHE = True\nUSE_MIXUP = True\nMIXUP_ALPHA = 0.2\nUSE_CUTMIX = True\nCUTMIX_ALPHA = 1.0\nLABEL_SMOOTHING = 0.05\nUSE_FOCAL_LOSS = False\nTTA_ROUNDS = 3\n\n# -------------------------\n# Optional: Focal loss (kept same)\n# -------------------------\ndef categorical_focal_loss(gamma=2.0, alpha=0.25):\n    def loss_fn(y_true, y_pred):\n        y_pred = tf.clip_by_value(y_pred, keras.backend.epsilon(), 1.0 - keras.backend.epsilon())\n        ce = -y_true * tf.math.log(y_pred)\n        weight = alpha * tf.pow(1 - y_pred, gamma)\n        loss = weight * ce\n        return tf.reduce_sum(loss, axis=-1)\n    return loss_fn\n\n# -------------------------\n# SEBlock (custom layer used in saved model / training)\n# -------------------------\nclass SEBlock(layers.Layer):\n    def __init__(self, se_ratio=0.25, **kwargs):\n        super().__init__(**kwargs)\n        self.se_ratio = se_ratio\n\n    def build(self, input_shape):\n        channels = int(input_shape[-1])\n        reduced = max(1, int(channels * self.se_ratio))\n        self.gap = layers.GlobalAveragePooling2D()\n        self.fc1 = layers.Dense(reduced, activation=\"relu\", kernel_initializer=\"he_normal\")\n        self.fc2 = layers.Dense(channels, activation=\"sigmoid\", kernel_initializer=\"he_normal\")\n        self.reshape = layers.Reshape((1, 1, channels))\n\n    def call(self, x):\n        se = self.gap(x)\n        se = self.fc1(se)\n        se = self.fc2(se)\n        se = self.reshape(se)\n        return x * se\n\n# -------------------------\n# Preprocessor (CLAHE + albumentations)\n# -------------------------\nclass Preprocessor:\n    def __init__(self, img_size=(380, 380), use_clahe=True):\n        self.img_size = img_size\n        self.use_clahe = use_clahe\n        if use_clahe:\n            try:\n                self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            except Exception:\n                self.clahe = None\n\n        self.train_aug = A.Compose([\n            A.Resize(img_size[0], img_size[1]),\n            A.RandomRotate90(p=0.15),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.1),\n            A.OneOf([\n                A.RandomBrightnessContrast(p=1.0),\n                A.HueSaturationValue(p=1.0)\n            ], p=0.6),\n            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.15, rotate_limit=15, p=0.6),\n            A.OneOf([A.GaussNoise(), A.ISONoise()], p=0.2),\n            A.OneOf([A.Blur(3), A.GaussianBlur(3)], p=0.2),\n            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n        ])\n\n        self.val_aug = A.Compose([\n            A.Resize(img_size[0], img_size[1]),\n            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n        ])\n\n    def apply_clahe(self, img):\n        if self.clahe is None:\n            return img\n        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n        lab[:, :, 0] = self.clahe.apply(lab[:, :, 0])\n        return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n\n    def preprocess(self, path_or_img, training=True):\n        if isinstance(path_or_img, str):\n            img = cv2.imread(path_or_img)\n            if img is None:\n                img = np.zeros((self.img_size[0], self.img_size[1], 3), dtype=np.uint8)\n            else:\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        else:\n            img = path_or_img\n\n        if self.use_clahe and img is not None:\n            try:\n                img = self.apply_clahe(img)\n            except Exception:\n                pass\n\n        aug = self.train_aug if training else self.val_aug\n        out = aug(image=img)['image']\n        return out.astype(np.float32)\n\n# -------------------------\n# Data generator (MixUp + CutMix)\n# -------------------------\nclass DataGenerator(keras.utils.Sequence):\n    def __init__(self, filepaths, labels, batch_size, preprocessor, num_classes,\n                 shuffle=True, mixup_prob=0.5, cutmix_prob=0.5, mixup_alpha=0.2, cutmix_alpha=1.0):\n        super().__init__()\n        self.filepaths = np.array(filepaths)\n        self.labels = np.array(labels)\n        self.batch_size = batch_size\n        self.prep = preprocessor\n        self.num_classes = num_classes\n        self.indexes = np.arange(len(self.filepaths))\n        self.shuffle = shuffle\n        self.on_epoch_end()\n        self.mixup_prob = mixup_prob\n        self.cutmix_prob = cutmix_prob\n        self.mixup_alpha = mixup_alpha\n        self.cutmix_alpha = cutmix_alpha\n\n    def __len__(self):\n        return int(np.ceil(len(self.filepaths) / self.batch_size))\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n    def _one_hot(self, idx):\n        lab = np.zeros(self.num_classes, dtype=np.float32)\n        lab[idx] = 1.0\n        return lab\n\n    def _mixup(self, x1, y1, x2, y2, alpha):\n        lam = np.random.beta(alpha, alpha) if alpha > 0 else 1.0\n        x = lam * x1 + (1 - lam) * x2\n        y = lam * y1 + (1 - lam) * y2\n        return x, y\n\n    def _cutmix(self, x1, y1, x2, y2, alpha):\n        H, W = x1.shape[:2]\n        lam = np.random.beta(alpha, alpha) if alpha > 0 else 1.0\n        cut_rat = math.sqrt(max(0.0, 1.0 - lam))\n        cut_w = int(W * cut_rat)\n        cut_h = int(H * cut_rat)\n        cx = np.random.randint(0, W)\n        cy = np.random.randint(0, H)\n        x1_copy = x1.copy()\n        x2_copy = x2.copy()\n        x1_copy[max(0, cy - cut_h // 2):max(0, cy - cut_h // 2) + cut_h,\n                max(0, cx - cut_w // 2):max(0, cx - cut_w // 2) + cut_w, :] = \\\n            x2_copy[max(0, cy - cut_h // 2):max(0, cy - cut_h // 2) + cut_h,\n                    max(0, cx - cut_w // 2):max(0, cx - cut_w // 2) + cut_w, :]\n        new_lam = 1.0 - (cut_w * cut_h) / (W * H) if (W * H) > 0 else 1.0\n        y = new_lam * y1 + (1.0 - new_lam) * y2\n        return x1_copy, y\n\n    def __getitem__(self, idx):\n        start = idx * self.batch_size\n        end = min((idx + 1) * self.batch_size, len(self.filepaths))\n        batch_inds = self.indexes[start:end]\n        bsize = len(batch_inds)\n        X = np.zeros((bsize, IMG_SIZE[0], IMG_SIZE[1], 3), dtype=np.float32)\n        Y = np.zeros((bsize, self.num_classes), dtype=np.float32)\n\n        for i, ind in enumerate(batch_inds):\n            img = self.prep.preprocess(self.filepaths[ind], training=True)\n            lbl = self._one_hot(self.labels[ind])\n            X[i] = img\n            Y[i] = lbl\n\n        if (USE_MIXUP or USE_CUTMIX) and bsize > 0:\n            for i in range(bsize):\n                p = np.random.rand()\n                j = np.random.randint(0, len(self.filepaths)) if len(self.filepaths) > 1 else batch_inds[i]\n                x2 = self.prep.preprocess(self.filepaths[j], training=True)\n                y2 = self._one_hot(self.labels[j])\n\n                if USE_CUTMIX and p < self.cutmix_prob:\n                    try:\n                        X[i], Y[i] = self._cutmix(X[i], Y[i], x2, y2, CUTMIX_ALPHA)\n                    except Exception:\n                        X[i], Y[i] = self._mixup(X[i], Y[i], x2, y2, MIXUP_ALPHA)\n                elif USE_MIXUP and p < self.mixup_prob:\n                    X[i], Y[i] = self._mixup(X[i], Y[i], x2, y2, MIXUP_ALPHA)\n        return X, Y\n# -------------------------\n# Load dataset (class folders)\n# -------------------------\ndef load_filepaths_labels(root):\n    root = Path(root)\n    if not root.exists():\n        raise FileNotFoundError(f\"DATA_DIR '{root}' does not exist.\")\n    class_dirs = sorted([d for d in root.iterdir() if d.is_dir()])\n    classes = [p.name for p in class_dirs]\n    filepaths, labels = [], []\n    for idx, dirp in enumerate(class_dirs):\n        for p in dirp.glob(\"*\"):\n            if p.suffix.lower() in (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"):\n                filepaths.append(str(p))\n                labels.append(idx)\n    return filepaths, labels, classes\n\nfilepaths, labels, classes = load_filepaths_labels(DATA_DIR)\nNUM_CLASSES = len(classes)\nprint(\"Classes:\", classes)\nprint(\"Total images:\", len(filepaths))\n\n# -------------------------\n# Duplicate detection (exact md5 + perceptual phash)\n# -------------------------\ndef md5_file(path):\n    h = hashlib.md5()\n    with open(path, \"rb\") as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            h.update(chunk)\n    return h.hexdigest()\n\n# Exact duplicates\nmd5_map = defaultdict(list)\nfor fp in filepaths:\n    try:\n        md = md5_file(fp)\n        md5_map[md].append(fp)\n    except Exception:\n        pass\nexact_duplicates = [v for v in md5_map.values() if len(v) > 1]\nprint(f\"Exact duplicate groups found: {len(exact_duplicates)}\")\nif len(exact_duplicates) > 0:\n    for g in exact_duplicates[:5]:\n        print(\"EXACT DUP GROUP (example):\", g)\n\n# Perceptual near-duplicates\nphash_map = defaultdict(list)\nfor fp in filepaths:\n    try:\n        h = str(imagehash.phash(Image.open(fp)))\n        phash_map[h].append(fp)\n    except Exception:\n        pass\nnear_duplicates = [v for v in phash_map.values() if len(v) > 1]\nprint(f\"Perceptual (phash) duplicate groups found: {len(near_duplicates)}\")\nif len(near_duplicates) > 0:\n    for g in near_duplicates[:5]:\n        print(\"NEAR DUP GROUP (example):\", g)\n\n# -------------------------\n# Remove all duplicates\n# -------------------------\ndup_paths = set()\nfor s in exact_duplicates + near_duplicates:\n    for p in s:\n        dup_paths.add(p)\n\nclean_filepaths = [fp for fp in filepaths if fp not in dup_paths]\nclean_labels = [labels[i] for i, fp in enumerate(filepaths) if fp not in dup_paths]\nprint(f\"After removing duplicates: {len(clean_filepaths)} images (removed {len(filepaths)-len(clean_filepaths)})\")\n\n# -------------------------\n# Split: train / val / test\n# -------------------------\ntrain_paths, temp_paths, train_labels, temp_labels = train_test_split(\n    clean_filepaths, clean_labels, test_size=0.30, random_state=SEED, stratify=clean_labels\n)\nval_paths, test_paths, val_labels, test_labels = train_test_split(\n    temp_paths, temp_labels, test_size=0.50, random_state=SEED, stratify=temp_labels\n)\nprint(\"Split sizes -> train:\", len(train_paths), \"val:\", len(val_paths), \"test:\", len(test_paths))\n\n# -------------------------\n# Compute class weights\n# -------------------------\ncw = compute_class_weight(\"balanced\", classes=np.unique(train_labels), y=np.array(train_labels))\nclass_weights = {i: float(w) for i, w in enumerate(cw)}\nprint(\"class_weights:\", class_weights)\n\n# -------------------------\n# Create generators\n# -------------------------\npreproc = Preprocessor(img_size=IMG_SIZE, use_clahe=USE_CLAHE)\ntrain_gen = DataGenerator(train_paths, train_labels, BATCH_SIZE, preproc, NUM_CLASSES,\n                          shuffle=True, mixup_prob=0.5 if USE_MIXUP else 0.0,\n                          cutmix_prob=0.5 if USE_CUTMIX else 0.0,\n                          mixup_alpha=MIXUP_ALPHA, cutmix_alpha=CUTMIX_ALPHA)\nval_gen = DataGenerator(val_paths, val_labels, BATCH_SIZE, preproc, NUM_CLASSES,\n                        shuffle=False, mixup_prob=0.0, cutmix_prob=0.0)\n\n# -------------------------\n# Model builder (EffNetB4 + SE + head)\n# -------------------------\ndef build_model(input_shape=(380, 380, 3), num_classes=4, dropout_rate=0.3):\n    inputs = keras.Input(shape=input_shape)\n    weights = \"imagenet\" if USE_IMAGENET else None\n    try:\n        base = EfficientNetB4(include_top=False, weights=weights, input_tensor=inputs)\n    except Exception as e:\n        print(\"EfficientNetB4 weight load failed; using random init. Error:\", e)\n        base = EfficientNetB4(include_top=False, weights=None, input_tensor=inputs)\n    x = base.output\n    x = SEBlock(se_ratio=0.25)(x)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(512, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(dropout_rate * 0.5)(x)\n    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n    model = keras.Model(inputs, outputs)\n    return model, base\n\nmodel, base = build_model(input_shape=(*IMG_SIZE, 3), num_classes=NUM_CLASSES)\nprint(\"Model params:\", model.count_params())\n\n# -------------------------\n# Loss and optimizer\n# -------------------------\nif USE_FOCAL_LOSS:\n    loss_fn = categorical_focal_loss(gamma=2.0, alpha=0.25)\nelse:\n    loss_fn = keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING)\n\ndef make_optimizer(lr):\n    return keras.optimizers.AdamW(learning_rate=float(lr), weight_decay=WEIGHT_DECAY)\n\nsteps_per_epoch = len(train_gen)\ntotal_steps = max(1, steps_per_epoch * (TOTAL_EPOCHS - WARMUP_EPOCHS))\n\n# -------------------------\n# Callbacks\n# -------------------------\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\n        os.path.join(OUTPUT_DIR, \"artifacts\", \"best_model.h5\"),\n        monitor=\"val_loss\",\n        save_best_only=True,\n        verbose=1\n    ),\n    keras.callbacks.ReduceLROnPlateau(\n        monitor=\"val_loss\",\n        factor=0.5,\n        patience=PATIENCE_RLR,\n        verbose=1,\n        min_lr=1e-7\n    ),\n    keras.callbacks.CSVLogger(os.path.join(OUTPUT_DIR, \"artifacts\", \"train_log.csv\"))\n]\n\nclass WarmupCosine(tf.keras.callbacks.Callback):\n    def __init__(self, warmup_epochs, initial_lr, total_steps, steps_per_epoch):\n        super().__init__()\n        self.warmup_epochs = warmup_epochs\n        self.initial_lr = float(initial_lr)\n        self.total_steps = max(1, total_steps)\n        self.steps_per_epoch = steps_per_epoch\n\n    def on_train_begin(self, logs=None):\n        self.step = 0\n\n    def on_batch_begin(self, batch, logs=None):\n        if self.step < self.warmup_epochs * self.steps_per_epoch:\n            warmup_total = float(self.warmup_epochs * self.steps_per_epoch)\n            lr = self.initial_lr * max(0.0, (self.step / warmup_total))\n        else:\n            t = (self.step - self.warmup_epochs * self.steps_per_epoch) / float(self.total_steps)\n            t = min(1.0, max(0.0, t))\n            lr = 0.5 * self.initial_lr * (1 + math.cos(math.pi * t))\n        try:\n            tf.keras.backend.set_value(self.model.optimizer.learning_rate, lr if lr > 0 else 1e-8)\n        except Exception:\n            try:\n                self.model.optimizer.learning_rate.assign(lr if lr > 0 else 1e-8)\n            except Exception:\n                pass\n        self.step += 1\n\n    def on_epoch_end(self, epoch, logs=None):\n        try:\n            current_lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n        except Exception:\n            current_lr = float(self.initial_lr)\n        print(f\"Epoch {epoch+1} lr={current_lr:.6e}\")\n\ncallbacks.append(WarmupCosine(WARMUP_EPOCHS, INITIAL_LR, total_steps, steps_per_epoch))\n\n# -------------------------\n# Phase 1: freeze base, train head\n# -------------------------\nfor layer in base.layers:\n    layer.trainable = False\n\noptimizer = make_optimizer(INITIAL_LR)\nmodel.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n\nprint(\"Phase 1 (warmup head only) training...\")\nhistory1 = model.fit(train_gen, validation_data=val_gen, epochs=WARMUP_EPOCHS,\n                     class_weight=class_weights, callbacks=callbacks, verbose=1)\n\n# -------------------------\n# Phase 2: unfreeze and fine-tune\n# -------------------------\nfor layer in base.layers:\n    layer.trainable = True\n\noptimizer2 = make_optimizer(INITIAL_LR * 0.5)\nmodel.compile(optimizer=optimizer2, loss=loss_fn, metrics=[\"accuracy\"])\n\nprint(\"Phase 2 (fine-tune full model) training...\")\ninitial_epoch = history1.epoch[-1] + 1 if hasattr(history1, \"epoch\") and len(history1.epoch) else 0\nhistory2 = model.fit(train_gen, validation_data=val_gen,\n                     epochs=(TOTAL_EPOCHS - WARMUP_EPOCHS), initial_epoch=initial_epoch,\n                     class_weight=class_weights, callbacks=callbacks, verbose=1)\n\n# Merge histories\nhistory = history1\nfor k, v in history2.history.items():\n    history.history.setdefault(k, []).extend(v)\n\n# -------------------------\n# Save final model\n# -------------------------\nfinal_path = os.path.join(OUTPUT_DIR, \"artifacts\", \"efnb4_se_final_clean.h5\")\ntry:\n    model.save(final_path)\n    print(\"Saved final model to:\", final_path)\nexcept Exception as e:\n    print(\"Model.save failed, saving weights only. Error:\", e)\n    model.save_weights(final_path + \".weights.h5\")\n\n# -------------------------\n# TTA evaluate on test set\n# -------------------------\ndef tta_predict(model, file_list, preprocessor, tta_rounds=3):\n    preds = []\n    for t in range(tta_rounds):\n        batch_preds = []\n        for i in range(0, len(file_list), BATCH_SIZE):\n            batch_files = file_list[i:i+BATCH_SIZE]\n            X = np.zeros((len(batch_files), IMG_SIZE[0], IMG_SIZE[1], 3), dtype=np.float32)\n            for j, fp in enumerate(batch_files):\n                X[j] = preprocessor.preprocess(fp, training=(t > 0))\n            p = model.predict(X, verbose=0)\n            batch_preds.append(p)\n        if len(batch_preds):\n            batch_preds = np.vstack(batch_preds)\n        else:\n            batch_preds = np.zeros((0, NUM_CLASSES), dtype=np.float32)\n        preds.append(batch_preds)\n    if len(preds) == 0:\n        return np.zeros((len(file_list), NUM_CLASSES), dtype=np.float32)\n    return np.mean(preds, axis=0)\n\ny_true = np.array(test_labels)\ny_prob_plain = tta_predict(model, test_paths, preproc, tta_rounds=1)\ny_pred_plain = np.argmax(y_prob_plain, axis=1)\nacc_plain = accuracy_score(y_true, y_pred_plain)\n\ny_prob_tta = tta_predict(model, test_paths, preproc, tta_rounds=TTA_ROUNDS)\ny_pred_tta = np.argmax(y_prob_tta, axis=1)\nacc_tta = accuracy_score(y_true, y_pred_tta)\n\n# -------------------------\n# Final summary output\n# -------------------------\nprint(\"\\n===== FINAL SUMMARY =====\")\nprint(\"Dataset classes:\", classes)\nprint(f\"Original images (before cleaning): {len(filepaths)}\")\nprint(f\"Images removed (duplicates & near duplicates): {len(filepaths) - len(clean_filepaths)}\")\nprint(f\"Images used (after cleaning): {len(clean_filepaths)}\")\nprint(f\"Train samples: {len(train_paths)}\")\nprint(f\"Validation samples: {len(val_paths)}\")\nprint(f\"Test samples: {len(test_paths)}\\n\")\n\nprint(f\"Test Accuracy (No TTA): {acc_plain*100:.2f}%\")\nprint(classification_report(y_true, y_pred_plain, target_names=classes, digits=4))\nprint(\"Confusion Matrix (No TTA):\\n\", confusion_matrix(y_true, y_pred_plain))\n\nprint(f\"\\nTest Accuracy (TTA={TTA_ROUNDS}): {acc_tta*100:.2f}%\")\nprint(classification_report(y_true, y_pred_tta, target_names=classes, digits=4))\nprint(\"Confusion Matrix (TTA):\\n\", confusion_matrix(y_true, y_pred_tta))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}
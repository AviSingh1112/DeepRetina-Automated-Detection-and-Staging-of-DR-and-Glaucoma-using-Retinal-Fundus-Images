{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4130910,"sourceType":"datasetVersion","datasetId":2440665}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Full fixed script. Set DATA_DIR at top and run.\nimport os\nimport math\nimport time\nimport random\nfrom pathlib import Path\nimport numpy as np\nimport cv2\nimport albumentations as A\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import EfficientNetB4\n\n# ---------------------\n# USER CONFIG - EDIT THIS\n# ---------------------\nDATA_DIR = \"/kaggle/input/eye-diseases-classification/dataset\"  # <<-- set your dataset root\nOUTPUT_DIR = \"/kaggle/working\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(os.path.join(OUTPUT_DIR, \"artifacts\"), exist_ok=True)\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\nIMG_SIZE = (380, 380)\nBATCH_SIZE = 16\nWARMUP_EPOCHS = 5\nTOTAL_EPOCHS = 80\nINITIAL_LR = 3e-4\nWEIGHT_DECAY = 1e-5\nPATIENCE_ES = 12\nPATIENCE_RLR = 6\n\nUSE_IMAGENET = True\nUSE_CLAHE = True\nUSE_MIXUP = True\nMIXUP_ALPHA = 0.2\nUSE_CUTMIX = True\nCUTMIX_ALPHA = 1.0\nLABEL_SMOOTHING = 0.05\nUSE_FOCAL_LOSS = False\nTTA_ROUNDS = 3\n\n# ---------------------\n# Utility: categorical focal loss (optional)\n# ---------------------\ndef categorical_focal_loss(gamma=2.0, alpha=0.25):\n    def loss_fn(y_true, y_pred):\n        y_pred = tf.clip_by_value(y_pred, keras.backend.epsilon(), 1.0 - keras.backend.epsilon())\n        ce = -y_true * tf.math.log(y_pred)\n        weight = alpha * tf.pow(1 - y_pred, gamma)\n        loss = weight * ce\n        return tf.reduce_sum(loss, axis=-1)\n    return loss_fn\n\n# ---------------------\n# SE block\n# ---------------------\nclass SEBlock(layers.Layer):\n    def __init__(self, se_ratio=0.25, **kwargs):\n        super().__init__(**kwargs)\n        self.se_ratio = se_ratio\n    def build(self, input_shape):\n        channels = int(input_shape[-1])\n        reduced = max(1, int(channels * self.se_ratio))\n        self.gap = layers.GlobalAveragePooling2D()\n        self.fc1 = layers.Dense(reduced, activation=\"relu\", kernel_initializer=\"he_normal\")\n        self.fc2 = layers.Dense(channels, activation=\"sigmoid\", kernel_initializer=\"he_normal\")\n        self.reshape = layers.Reshape((1,1,channels))\n    def call(self, x):\n        se = self.gap(x)\n        se = self.fc1(se)\n        se = self.fc2(se)\n        se = self.reshape(se)\n        return x * se\n\n# ---------------------\n# Preprocessor\n# ---------------------\nclass Preprocessor:\n    def __init__(self, img_size=(380,380), use_clahe=True):\n        self.img_size = img_size\n        self.use_clahe = use_clahe\n        if use_clahe:\n            try:\n                self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n            except Exception:\n                self.clahe = None\n        self.train_aug = A.Compose([\n            A.Resize(img_size[0], img_size[1]),\n            A.RandomRotate90(p=0.15),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.1),\n            A.OneOf([A.RandomBrightnessContrast(p=1.0), A.HueSaturationValue(p=1.0)], p=0.6),\n            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.15, rotate_limit=15, p=0.6),\n            A.OneOf([A.GaussNoise(), A.ISONoise()], p=0.2),\n            A.OneOf([A.Blur(3), A.GaussianBlur(3)], p=0.2),\n            A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225))\n        ])\n        self.val_aug = A.Compose([\n            A.Resize(img_size[0], img_size[1]),\n            A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225))\n        ])\n    def apply_clahe(self, img):\n        if self.clahe is None:\n            return img\n        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n        lab[:,:,0] = self.clahe.apply(lab[:,:,0])\n        return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n    def preprocess(self, path_or_img, training=True):\n        if isinstance(path_or_img, str):\n            img = cv2.imread(path_or_img)\n            if img is None:\n                img = np.zeros((self.img_size[0], self.img_size[1], 3), dtype=np.uint8)\n            else:\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        else:\n            img = path_or_img\n        if self.use_clahe and img is not None:\n            try:\n                img = self.apply_clahe(img)\n            except Exception:\n                pass\n        aug = self.train_aug if training else self.val_aug\n        out = aug(image=img)['image']\n        # albumentations returns float32 already for Normalize; ensure dtype\n        return out.astype(np.float32)\n\n# ---------------------\n# Data generator with MixUp/CutMix\n# ---------------------\nclass DataGenerator(keras.utils.Sequence):\n    def __init__(self, filepaths, labels, batch_size, preprocessor, num_classes, shuffle=True,\n                 mixup_prob=0.5, cutmix_prob=0.5, mixup_alpha=0.2, cutmix_alpha=1.0):\n        super().__init__()\n        self.filepaths = np.array(filepaths)\n        self.labels = np.array(labels)\n        self.batch_size = batch_size\n        self.prep = preprocessor\n        self.num_classes = num_classes\n        self.indexes = np.arange(len(self.filepaths))\n        self.shuffle = shuffle\n        self.on_epoch_end()\n        self.mixup_prob = mixup_prob\n        self.cutmix_prob = cutmix_prob\n        self.mixup_alpha = mixup_alpha\n        self.cutmix_alpha = cutmix_alpha\n    def __len__(self):\n        return int(np.ceil(len(self.filepaths) / self.batch_size))\n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n    def _one_hot(self, idx):\n        lab = np.zeros(self.num_classes, dtype=np.float32)\n        lab[idx] = 1.0\n        return lab\n    def _mixup(self, x1, y1, x2, y2, alpha):\n        lam = np.random.beta(alpha, alpha) if alpha > 0 else 1.0\n        x = lam * x1 + (1 - lam) * x2\n        y = lam * y1 + (1 - lam) * y2\n        return x, y\n    def _cutmix(self, x1, y1, x2, y2, alpha):\n        H, W = x1.shape[:2]\n        lam = np.random.beta(alpha, alpha) if alpha > 0 else 1.0\n        cut_rat = math.sqrt(max(0.0, 1.0 - lam))\n        cut_w = int(W * cut_rat)\n        cut_h = int(H * cut_rat)\n        cx = np.random.randint(0, W)\n        cy = np.random.randint(0, H)\n        x1_copy = x1.copy()\n        x2_copy = x2.copy()\n        x1_copy[max(0, cy - cut_h//2):max(0, cy - cut_h//2) + cut_h,\n                max(0, cx - cut_w//2):max(0, cx - cut_w//2) + cut_w, :] = \\\n            x2_copy[max(0, cy - cut_h//2):max(0, cy - cut_h//2) + cut_h,\n                    max(0, cx - cut_w//2):max(0, cx - cut_w//2) + cut_w, :]\n        new_lam = 1.0 - (cut_w * cut_h) / (W * H) if (W*H)>0 else 1.0\n        y = new_lam * y1 + (1.0 - new_lam) * y2\n        return x1_copy, y\n    def __getitem__(self, idx):\n        start = idx * self.batch_size\n        end = min((idx + 1) * self.batch_size, len(self.filepaths))\n        batch_inds = self.indexes[start:end]\n        bsize = len(batch_inds)\n        X = np.zeros((bsize, IMG_SIZE[0], IMG_SIZE[1], 3), dtype=np.float32)\n        Y = np.zeros((bsize, self.num_classes), dtype=np.float32)\n        for i, ind in enumerate(batch_inds):\n            img = self.prep.preprocess(self.filepaths[ind], training=True)\n            lbl = self._one_hot(self.labels[ind])\n            X[i] = img\n            Y[i] = lbl\n        if (USE_MIXUP or USE_CUTMIX) and bsize > 0:\n            for i in range(bsize):\n                p = np.random.rand()\n                if len(self.filepaths) > 1:\n                    # sample a different index\n                    j = np.random.randint(0, len(self.filepaths))\n                    # avoid same index; if same, allow but try a few times\n                    tries = 0\n                    while j == batch_inds[i] and tries < 5:\n                        j = np.random.randint(0, len(self.filepaths))\n                        tries += 1\n                else:\n                    j = batch_inds[i]\n                x2 = self.prep.preprocess(self.filepaths[j], training=True)\n                y2 = self._one_hot(self.labels[j])\n                if USE_CUTMIX and p < self.cutmix_prob:\n                    try:\n                        X[i], Y[i] = self._cutmix(X[i], Y[i], x2, y2, CUTMIX_ALPHA)\n                    except Exception:\n                        X[i], Y[i] = self._mixup(X[i], Y[i], x2, y2, MIXUP_ALPHA)\n                elif USE_MIXUP and p < self.mixup_prob:\n                    X[i], Y[i] = self._mixup(X[i], Y[i], x2, y2, MIXUP_ALPHA)\n        return X, Y\n\n# ---------------------\n# Load filepaths & labels\n# ---------------------\ndef load_filepaths_labels(root):\n    root = Path(root)\n    if not root.exists():\n        raise FileNotFoundError(f\"DATA_DIR '{root}' does not exist. Update DATA_DIR.\")\n    class_dirs = sorted([d for d in root.iterdir() if d.is_dir()])\n    if len(class_dirs) == 0:\n        raise FileNotFoundError(f\"No class subfolders found under {root}.\")\n    classes = [p.name for p in class_dirs]\n    filepaths = []\n    labels = []\n    for idx, dirp in enumerate(class_dirs):\n        for p in dirp.glob(\"*\"):\n            if p.suffix.lower() in (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"):\n                filepaths.append(str(p))\n                labels.append(idx)\n    return filepaths, labels, classes\n\nfilepaths, labels, classes = load_filepaths_labels(DATA_DIR)\nNUM_CLASSES = len(classes)\nprint(\"Classes:\", classes)\nprint(\"Total images:\", len(filepaths))\n\n# Train/val/test split\ntrain_paths, temp_paths, train_labels, temp_labels = train_test_split(\n    filepaths, labels, test_size=0.30, random_state=SEED, stratify=labels)\nval_paths, test_paths, val_labels, test_labels = train_test_split(\n    temp_paths, temp_labels, test_size=0.50, random_state=SEED, stratify=temp_labels)\n\nprint(\"Train/Val/Test:\", len(train_paths), len(val_paths), len(test_paths))\n\ncw = compute_class_weight(\"balanced\", classes=np.unique(train_labels), y=np.array(train_labels))\nclass_weights = {i: float(w) for i,w in enumerate(cw)}\nprint(\"class_weights:\", class_weights)\n\n# Generators\npreproc = Preprocessor(img_size=IMG_SIZE, use_clahe=USE_CLAHE)\ntrain_gen = DataGenerator(train_paths, train_labels, BATCH_SIZE, preproc, NUM_CLASSES,\n                          shuffle=True,\n                          mixup_prob=0.5 if USE_MIXUP else 0.0,\n                          cutmix_prob=0.5 if USE_CUTMIX else 0.0,\n                          mixup_alpha=MIXUP_ALPHA, cutmix_alpha=CUTMIX_ALPHA)\nval_gen = DataGenerator(val_paths, val_labels, BATCH_SIZE, preproc, NUM_CLASSES, shuffle=False,\n                        mixup_prob=0.0, cutmix_prob=0.0)\n\n# ---------------------\n# Build model\n# ---------------------\ndef build_model(input_shape=(380,380,3), num_classes=4, dropout_rate=0.3):\n    inputs = keras.Input(shape=input_shape)\n    weights = \"imagenet\" if USE_IMAGENET else None\n    try:\n        base = EfficientNetB4(include_top=False, weights=weights, input_tensor=inputs)\n    except Exception as e:\n        # fallback: include_top=False with random init\n        print(\"EfficientNetB4 weight load failed; using random init. Error:\", e)\n        base = EfficientNetB4(include_top=False, weights=None, input_tensor=inputs)\n    x = base.output\n    x = SEBlock(se_ratio=0.25)(x)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(512, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(dropout_rate*0.5)(x)\n    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n    model = keras.Model(inputs, outputs)\n    return model, base\n\nmodel, base = build_model(input_shape=(*IMG_SIZE,3), num_classes=NUM_CLASSES)\nprint(\"Model params:\", model.count_params())\n\n# ---------------------\n# Loss and optimizer factory\n# ---------------------\nif USE_FOCAL_LOSS:\n    loss_fn = categorical_focal_loss(gamma=2.0, alpha=0.25)\nelse:\n    loss_fn = keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING)\n\ndef make_optimizer(lr):\n    # pass float to optimizer\n    return keras.optimizers.AdamW(learning_rate=float(lr), weight_decay=WEIGHT_DECAY)\n\nsteps_per_epoch = len(train_gen)\ntotal_steps = max(1, steps_per_epoch * (TOTAL_EPOCHS - WARMUP_EPOCHS))\n\n# ---------------------\n# Callbacks, including WarmupCosine (updates optimizer.learning_rate)\n# ---------------------\nos.makedirs(os.path.join(OUTPUT_DIR, \"artifacts\"), exist_ok=True)\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(os.path.join(OUTPUT_DIR, \"artifacts\", \"best_model.h5\"),\n                                    monitor=\"val_loss\", save_best_only=True, verbose=1),\n    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE_ES, restore_best_weights=True, verbose=1),\n    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=PATIENCE_RLR, verbose=1, min_lr=1e-7),\n    keras.callbacks.CSVLogger(os.path.join(OUTPUT_DIR, \"artifacts\", \"train_log.csv\"))\n]\n\nclass WarmupCosine(tf.keras.callbacks.Callback):\n    def __init__(self, warmup_epochs, initial_lr, total_steps, steps_per_epoch):\n        super().__init__()\n        self.warmup_epochs = warmup_epochs\n        self.initial_lr = float(initial_lr)\n        self.total_steps = max(1, total_steps)\n        self.steps_per_epoch = steps_per_epoch\n    def on_train_begin(self, logs=None):\n        self.step = 0\n    def on_batch_begin(self, batch, logs=None):\n        if self.step < self.warmup_epochs * self.steps_per_epoch:\n            warmup_total = float(self.warmup_epochs * self.steps_per_epoch)\n            lr = self.initial_lr * max(0.0, (self.step / warmup_total))\n        else:\n            t = (self.step - self.warmup_epochs * self.steps_per_epoch) / float(self.total_steps)\n            t = min(1.0, max(0.0, t))\n            lr = 0.5 * self.initial_lr * (1 + math.cos(math.pi * t))\n        # Update optimizer learning rate safely\n        try:\n            tf.keras.backend.set_value(self.model.optimizer.learning_rate, lr if lr>0 else 1e-8)\n        except Exception:\n            try:\n                self.model.optimizer.learning_rate.assign(lr if lr>0 else 1e-8)\n            except Exception:\n                pass\n        self.step += 1\n    def on_epoch_end(self, epoch, logs=None):\n        try:\n            current_lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n        except Exception:\n            current_lr = float(self.initial_lr)\n        print(f\"Epoch {epoch+1} lr={current_lr:.6e}\")\n\ncallbacks.append(WarmupCosine(warmup_epochs=WARMUP_EPOCHS, initial_lr=INITIAL_LR,\n                             total_steps=total_steps, steps_per_epoch=steps_per_epoch))\n\n# ---------------------\n# Phase 1: freeze base, train head\n# ---------------------\nfor layer in base.layers:\n    layer.trainable = False\n\noptimizer = make_optimizer(INITIAL_LR)\nmodel.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\nprint(\"Phase 1 (warmup head only) training...\")\nhistory1 = model.fit(train_gen, validation_data=val_gen, epochs=WARMUP_EPOCHS,\n                     class_weight=class_weights, callbacks=callbacks, verbose=1)\n\n# ---------------------\n# Phase 2: unfreeze and fine-tune\n# ---------------------\nfor layer in base.layers:\n    layer.trainable = True\n\n# re-create optimizer with lower LR for fine-tune (or reuse & assign)\noptimizer2 = make_optimizer(INITIAL_LR * 0.5)\nmodel.compile(optimizer=optimizer2, loss=loss_fn, metrics=[\"accuracy\"])\nprint(\"Phase 2 (fine-tune full model) training...\")\ninitial_epoch = history1.epoch[-1] + 1 if hasattr(history1, \"epoch\") and len(history1.epoch) else 0\nhistory2 = model.fit(train_gen, validation_data=val_gen,\n                     epochs=(TOTAL_EPOCHS - WARMUP_EPOCHS),\n                     initial_epoch=initial_epoch,\n                     class_weight=class_weights, callbacks=callbacks, verbose=1)\n\n# Merge histories for simple analysis\nhistory = history1\nfor k, v in history2.history.items():\n    history.history.setdefault(k, []).extend(v)\n\n# Save final model\nfinal_path = os.path.join(OUTPUT_DIR, \"artifacts\", \"efnb4_se_final.h5\")\ntry:\n    model.save(final_path)\n    print(\"Saved final model to:\", final_path)\nexcept Exception as e:\n    print(\"Model.save failed, saving weights only. Error:\", e)\n    model.save_weights(final_path + \".weights.h5\")\n\n# ---------------------\n# TTA evaluate on test set\n# ---------------------\ndef tta_predict(model, file_list, preprocessor, tta_rounds=3):\n    preds = []\n    for t in range(tta_rounds):\n        batch_preds = []\n        for i in range(0, len(file_list), BATCH_SIZE):\n            batch_files = file_list[i:i+BATCH_SIZE]\n            X = np.zeros((len(batch_files), IMG_SIZE[0], IMG_SIZE[1], 3), dtype=np.float32)\n            for j, fp in enumerate(batch_files):\n                X[j] = preprocessor.preprocess(fp, training=(t>0))\n            p = model.predict(X, verbose=0)\n            batch_preds.append(p)\n        if len(batch_preds):\n            batch_preds = np.vstack(batch_preds)\n        else:\n            batch_preds = np.zeros((0, NUM_CLASSES), dtype=np.float32)\n        preds.append(batch_preds)\n    if len(preds) == 0:\n        return np.zeros((len(file_list), NUM_CLASSES), dtype=np.float32)\n    return np.mean(preds, axis=0)\n\ny_true = np.array(test_labels)\ny_prob = tta_predict(model, test_paths, preproc, tta_rounds=TTA_ROUNDS)\ny_pred = np.argmax(y_prob, axis=1)\nacc = accuracy_score(y_true, y_pred)\nprint(f\"\\nTTA TEST Accuracy: {acc*100:.2f}%\\n\")\nprint(classification_report(y_true, y_pred, target_names=classes, digits=4))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-02T07:50:41.977397Z","iopub.execute_input":"2025-10-02T07:50:41.978223Z","iopub.status.idle":"2025-10-02T10:43:08.002422Z","shell.execute_reply.started":"2025-10-02T07:50:41.978188Z","shell.execute_reply":"2025-10-02T10:43:08.001738Z"}},"outputs":[{"name":"stderr","text":"2025-10-02 07:50:49.351033: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759391449.543066      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759391449.601811      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Classes: ['cataract', 'diabetic_retinopathy', 'glaucoma', 'normal']\nTotal images: 4217\nTrain/Val/Test: 2951 633 633\nclass_weights: {0: 1.0161845730027548, 1: 0.9606119791666666, 2: 1.04645390070922, 3: 0.9810505319148937}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\nI0000 00:00:1759391461.246600      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1759391461.247336      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n\u001b[1m71686520/71686520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nModel params: 20203811\nPhase 1 (warmup head only) training...\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1759391499.895731     101 service.cc:148] XLA service 0x7e830801c8f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1759391499.896421     101 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1759391499.896441     101 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1759391503.794441     101 cuda_dnn.cc:529] Loaded cuDNN version 90300\nE0000 00:00:1759391508.800196     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759391508.981570     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  1/185\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54:08\u001b[0m 57s/step - accuracy: 0.3125 - loss: 1.9742","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1759391524.255687     101 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m184/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.2911 - loss: 1.7644","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1759391646.472431     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759391646.627149     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742ms/step - accuracy: 0.2914 - loss: 1.7638","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1759391702.250282      99 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759391702.411187      99 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_loss improved from inf to 1.24734, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 1 lr=5.967568e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 1s/step - accuracy: 0.2916 - loss: 1.7632 - val_accuracy: 0.4834 - val_loss: 1.2473 - learning_rate: 5.9676e-05\nEpoch 2/5\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552ms/step - accuracy: 0.3972 - loss: 1.4841\nEpoch 2: val_loss improved from 1.24734 to 1.06716, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 2 lr=1.196757e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 682ms/step - accuracy: 0.3973 - loss: 1.4838 - val_accuracy: 0.6161 - val_loss: 1.0672 - learning_rate: 1.1968e-04\nEpoch 3/5\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - accuracy: 0.4480 - loss: 1.3570\nEpoch 3: val_loss improved from 1.06716 to 0.99791, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 3 lr=1.796757e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 672ms/step - accuracy: 0.4479 - loss: 1.3569 - val_accuracy: 0.5798 - val_loss: 0.9979 - learning_rate: 1.7968e-04\nEpoch 4/5\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - accuracy: 0.4561 - loss: 1.3092\nEpoch 4: val_loss did not improve from 0.99791\nEpoch 4 lr=2.396757e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 660ms/step - accuracy: 0.4562 - loss: 1.3092 - val_accuracy: 0.4502 - val_loss: 1.1717 - learning_rate: 2.3968e-04\nEpoch 5/5\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - accuracy: 0.4855 - loss: 1.2699\nEpoch 5: val_loss did not improve from 0.99791\nEpoch 5 lr=2.996757e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 668ms/step - accuracy: 0.4855 - loss: 1.2699 - val_accuracy: 0.5735 - val_loss: 1.0794 - learning_rate: 2.9968e-04\nRestoring model weights from the end of the best epoch: 3.\nPhase 2 (fine-tune full model) training...\nEpoch 6/75\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1759392347.757411     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392347.903404     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392348.362715     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392348.508890     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392349.046409     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392349.200042     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392349.874196     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392350.026699     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392350.337174     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392350.490322     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392350.953205     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392351.133715     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 88/185\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m57s\u001b[0m 588ms/step - accuracy: 0.2822 - loss: 1.9149","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1759392463.416960     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392463.553117     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392463.856180     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392463.992305     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392464.406645     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392464.547467     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392465.039085     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1759392465.192195     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930ms/step - accuracy: 0.3216 - loss: 1.7712\nEpoch 6: val_loss did not improve from 0.99791\nEpoch 6 lr=5.967568e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 1s/step - accuracy: 0.3220 - loss: 1.7700 - val_accuracy: 0.4566 - val_loss: 1.2567 - learning_rate: 5.9676e-05\nEpoch 7/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.5598 - loss: 1.2208\nEpoch 7: val_loss improved from 0.99791 to 0.97338, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 7 lr=1.196757e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 725ms/step - accuracy: 0.5600 - loss: 1.2205 - val_accuracy: 0.6240 - val_loss: 0.9734 - learning_rate: 1.1968e-04\nEpoch 8/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.6564 - loss: 1.0374\nEpoch 8: val_loss improved from 0.97338 to 0.68331, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 8 lr=1.796757e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 735ms/step - accuracy: 0.6564 - loss: 1.0373 - val_accuracy: 0.7852 - val_loss: 0.6833 - learning_rate: 1.7968e-04\nEpoch 9/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.6633 - loss: 0.9843\nEpoch 9: val_loss improved from 0.68331 to 0.68016, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 9 lr=2.396757e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 746ms/step - accuracy: 0.6634 - loss: 0.9843 - val_accuracy: 0.8057 - val_loss: 0.6802 - learning_rate: 2.3968e-04\nEpoch 10/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598ms/step - accuracy: 0.7154 - loss: 0.8913\nEpoch 10: val_loss did not improve from 0.68016\nEpoch 10 lr=2.996757e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 731ms/step - accuracy: 0.7154 - loss: 0.8913 - val_accuracy: 0.7757 - val_loss: 0.8103 - learning_rate: 2.9968e-04\nEpoch 11/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581ms/step - accuracy: 0.7359 - loss: 0.8469\nEpoch 11: val_loss improved from 0.68016 to 0.57669, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 11 lr=2.998698e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 723ms/step - accuracy: 0.7359 - loss: 0.8468 - val_accuracy: 0.8310 - val_loss: 0.5767 - learning_rate: 2.9987e-04\nEpoch 12/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step - accuracy: 0.7637 - loss: 0.7968\nEpoch 12: val_loss did not improve from 0.57669\nEpoch 12 lr=2.994768e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 710ms/step - accuracy: 0.7636 - loss: 0.7969 - val_accuracy: 0.8246 - val_loss: 0.5835 - learning_rate: 2.9948e-04\nEpoch 13/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587ms/step - accuracy: 0.7629 - loss: 0.7931\nEpoch 13: val_loss did not improve from 0.57669\nEpoch 13 lr=2.988215e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 714ms/step - accuracy: 0.7630 - loss: 0.7929 - val_accuracy: 0.8341 - val_loss: 0.5930 - learning_rate: 2.9882e-04\nEpoch 14/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - accuracy: 0.7804 - loss: 0.7588\nEpoch 14: val_loss improved from 0.57669 to 0.48379, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 14 lr=2.979051e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 715ms/step - accuracy: 0.7804 - loss: 0.7587 - val_accuracy: 0.8784 - val_loss: 0.4838 - learning_rate: 2.9791e-04\nEpoch 15/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576ms/step - accuracy: 0.8038 - loss: 0.7555\nEpoch 15: val_loss did not improve from 0.48379\nEpoch 15 lr=2.967292e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 705ms/step - accuracy: 0.8038 - loss: 0.7554 - val_accuracy: 0.8736 - val_loss: 0.4984 - learning_rate: 2.9673e-04\nEpoch 16/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step - accuracy: 0.8078 - loss: 0.7063\nEpoch 16: val_loss improved from 0.48379 to 0.42522, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 16 lr=2.952959e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 721ms/step - accuracy: 0.8079 - loss: 0.7063 - val_accuracy: 0.9179 - val_loss: 0.4252 - learning_rate: 2.9530e-04\nEpoch 17/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.8086 - loss: 0.7228\nEpoch 17: val_loss did not improve from 0.42522\nEpoch 17 lr=2.936077e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 721ms/step - accuracy: 0.8086 - loss: 0.7227 - val_accuracy: 0.9131 - val_loss: 0.4755 - learning_rate: 2.9361e-04\nEpoch 18/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.8243 - loss: 0.6882\nEpoch 18: val_loss did not improve from 0.42522\nEpoch 18 lr=2.916676e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 714ms/step - accuracy: 0.8243 - loss: 0.6882 - val_accuracy: 0.8910 - val_loss: 0.4776 - learning_rate: 2.9167e-04\nEpoch 19/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.8048 - loss: 0.6985\nEpoch 19: val_loss did not improve from 0.42522\nEpoch 19 lr=2.894790e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 718ms/step - accuracy: 0.8048 - loss: 0.6985 - val_accuracy: 0.7930 - val_loss: 0.6862 - learning_rate: 2.8948e-04\nEpoch 20/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - accuracy: 0.8430 - loss: 0.6574\nEpoch 20: val_loss did not improve from 0.42522\nEpoch 20 lr=2.870456e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 707ms/step - accuracy: 0.8430 - loss: 0.6574 - val_accuracy: 0.8926 - val_loss: 0.4803 - learning_rate: 2.8705e-04\nEpoch 21/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596ms/step - accuracy: 0.8352 - loss: 0.6442\nEpoch 21: val_loss did not improve from 0.42522\nEpoch 21 lr=2.843719e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 723ms/step - accuracy: 0.8352 - loss: 0.6442 - val_accuracy: 0.9084 - val_loss: 0.4376 - learning_rate: 2.8437e-04\nEpoch 22/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step - accuracy: 0.8431 - loss: 0.6536\nEpoch 22: val_loss improved from 0.42522 to 0.42419, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 22 lr=2.814624e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 718ms/step - accuracy: 0.8431 - loss: 0.6536 - val_accuracy: 0.9068 - val_loss: 0.4242 - learning_rate: 2.8146e-04\nEpoch 23/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.8486 - loss: 0.6282\nEpoch 23: val_loss did not improve from 0.42419\nEpoch 23 lr=2.783222e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 709ms/step - accuracy: 0.8486 - loss: 0.6282 - val_accuracy: 0.8799 - val_loss: 0.4910 - learning_rate: 2.7832e-04\nEpoch 24/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step - accuracy: 0.8519 - loss: 0.6163\nEpoch 24: val_loss did not improve from 0.42419\nEpoch 24 lr=2.749570e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 700ms/step - accuracy: 0.8519 - loss: 0.6164 - val_accuracy: 0.8989 - val_loss: 0.4464 - learning_rate: 2.7496e-04\nEpoch 25/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584ms/step - accuracy: 0.8507 - loss: 0.6250\nEpoch 25: val_loss did not improve from 0.42419\nEpoch 25 lr=2.713725e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 707ms/step - accuracy: 0.8507 - loss: 0.6250 - val_accuracy: 0.9068 - val_loss: 0.4362 - learning_rate: 2.7137e-04\nEpoch 26/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.8631 - loss: 0.6250\nEpoch 26: val_loss did not improve from 0.42419\nEpoch 26 lr=2.675751e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 692ms/step - accuracy: 0.8630 - loss: 0.6250 - val_accuracy: 0.8136 - val_loss: 0.6997 - learning_rate: 2.6758e-04\nEpoch 27/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583ms/step - accuracy: 0.8541 - loss: 0.6111\nEpoch 27: val_loss did not improve from 0.42419\nEpoch 27 lr=2.635714e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 704ms/step - accuracy: 0.8540 - loss: 0.6112 - val_accuracy: 0.9100 - val_loss: 0.4367 - learning_rate: 2.6357e-04\nEpoch 28/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - accuracy: 0.8462 - loss: 0.6280\nEpoch 28: val_loss did not improve from 0.42419\n\nEpoch 28: ReduceLROnPlateau reducing learning rate to 0.0001296842674491927.\nEpoch 28 lr=1.296843e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 703ms/step - accuracy: 0.8463 - loss: 0.6279 - val_accuracy: 0.8483 - val_loss: 0.5834 - learning_rate: 2.5937e-04\nEpoch 29/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585ms/step - accuracy: 0.8621 - loss: 0.5969\nEpoch 29: val_loss improved from 0.42419 to 0.39660, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 29 lr=2.549738e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 720ms/step - accuracy: 0.8621 - loss: 0.5970 - val_accuracy: 0.9258 - val_loss: 0.3966 - learning_rate: 2.5497e-04\nEpoch 30/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.8704 - loss: 0.5929\nEpoch 30: val_loss did not improve from 0.39660\nEpoch 30 lr=2.503948e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 721ms/step - accuracy: 0.8704 - loss: 0.5929 - val_accuracy: 0.9147 - val_loss: 0.4305 - learning_rate: 2.5039e-04\nEpoch 31/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582ms/step - accuracy: 0.8597 - loss: 0.6226\nEpoch 31: val_loss did not improve from 0.39660\nEpoch 31 lr=2.456398e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 711ms/step - accuracy: 0.8597 - loss: 0.6226 - val_accuracy: 0.9115 - val_loss: 0.4138 - learning_rate: 2.4564e-04\nEpoch 32/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584ms/step - accuracy: 0.8457 - loss: 0.6353\nEpoch 32: val_loss did not improve from 0.39660\nEpoch 32 lr=2.407169e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 709ms/step - accuracy: 0.8457 - loss: 0.6352 - val_accuracy: 0.9289 - val_loss: 0.4183 - learning_rate: 2.4072e-04\nEpoch 33/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.8758 - loss: 0.5866\nEpoch 33: val_loss did not improve from 0.39660\nEpoch 33 lr=2.356349e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 692ms/step - accuracy: 0.8758 - loss: 0.5866 - val_accuracy: 0.8926 - val_loss: 0.4571 - learning_rate: 2.3563e-04\nEpoch 34/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583ms/step - accuracy: 0.8653 - loss: 0.5818\nEpoch 34: val_loss did not improve from 0.39660\nEpoch 34 lr=2.304027e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 709ms/step - accuracy: 0.8653 - loss: 0.5818 - val_accuracy: 0.8310 - val_loss: 0.5968 - learning_rate: 2.3040e-04\nEpoch 35/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step - accuracy: 0.8817 - loss: 0.5799\nEpoch 35: val_loss did not improve from 0.39660\n\nEpoch 35: ReduceLROnPlateau reducing learning rate to 0.00011251470277784392.\nEpoch 35 lr=1.125147e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 713ms/step - accuracy: 0.8816 - loss: 0.5799 - val_accuracy: 0.8452 - val_loss: 0.5814 - learning_rate: 2.2503e-04\nEpoch 36/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597ms/step - accuracy: 0.8578 - loss: 0.5759\nEpoch 36: val_loss improved from 0.39660 to 0.38181, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 36 lr=2.195245e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 742ms/step - accuracy: 0.8578 - loss: 0.5759 - val_accuracy: 0.9194 - val_loss: 0.3818 - learning_rate: 2.1952e-04\nEpoch 37/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - accuracy: 0.8738 - loss: 0.5696\nEpoch 37: val_loss did not improve from 0.38181\nEpoch 37 lr=2.138976e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 703ms/step - accuracy: 0.8739 - loss: 0.5696 - val_accuracy: 0.9147 - val_loss: 0.4105 - learning_rate: 2.1390e-04\nEpoch 38/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603ms/step - accuracy: 0.8710 - loss: 0.5659\nEpoch 38: val_loss improved from 0.38181 to 0.37410, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 38 lr=2.081586e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 744ms/step - accuracy: 0.8710 - loss: 0.5660 - val_accuracy: 0.9368 - val_loss: 0.3741 - learning_rate: 2.0816e-04\nEpoch 39/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584ms/step - accuracy: 0.8742 - loss: 0.5714\nEpoch 39: val_loss improved from 0.37410 to 0.36817, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 39 lr=2.023176e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 718ms/step - accuracy: 0.8743 - loss: 0.5713 - val_accuracy: 0.9321 - val_loss: 0.3682 - learning_rate: 2.0232e-04\nEpoch 40/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - accuracy: 0.8875 - loss: 0.5439\nEpoch 40: val_loss did not improve from 0.36817\nEpoch 40 lr=1.963848e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 700ms/step - accuracy: 0.8875 - loss: 0.5439 - val_accuracy: 0.9226 - val_loss: 0.3763 - learning_rate: 1.9638e-04\nEpoch 41/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584ms/step - accuracy: 0.8898 - loss: 0.5478\nEpoch 41: val_loss did not improve from 0.36817\nEpoch 41 lr=1.903707e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 713ms/step - accuracy: 0.8899 - loss: 0.5477 - val_accuracy: 0.9131 - val_loss: 0.3900 - learning_rate: 1.9037e-04\nEpoch 42/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614ms/step - accuracy: 0.8707 - loss: 0.5508\nEpoch 42: val_loss did not improve from 0.36817\nEpoch 42 lr=1.842857e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 746ms/step - accuracy: 0.8708 - loss: 0.5508 - val_accuracy: 0.8720 - val_loss: 0.5143 - learning_rate: 1.8429e-04\nEpoch 43/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.8968 - loss: 0.5459\nEpoch 43: val_loss did not improve from 0.36817\nEpoch 43 lr=1.781406e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 711ms/step - accuracy: 0.8968 - loss: 0.5459 - val_accuracy: 0.9258 - val_loss: 0.3888 - learning_rate: 1.7814e-04\nEpoch 44/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571ms/step - accuracy: 0.8934 - loss: 0.5434\nEpoch 44: val_loss improved from 0.36817 to 0.36191, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 44 lr=1.719461e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 705ms/step - accuracy: 0.8934 - loss: 0.5434 - val_accuracy: 0.9447 - val_loss: 0.3619 - learning_rate: 1.7195e-04\nEpoch 45/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - accuracy: 0.8926 - loss: 0.5388\nEpoch 45: val_loss did not improve from 0.36191\nEpoch 45 lr=1.657130e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 702ms/step - accuracy: 0.8926 - loss: 0.5388 - val_accuracy: 0.9242 - val_loss: 0.3905 - learning_rate: 1.6571e-04\nEpoch 46/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581ms/step - accuracy: 0.9013 - loss: 0.5485\nEpoch 46: val_loss did not improve from 0.36191\nEpoch 46 lr=1.594525e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 700ms/step - accuracy: 0.9013 - loss: 0.5484 - val_accuracy: 0.9415 - val_loss: 0.3662 - learning_rate: 1.5945e-04\nEpoch 47/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step - accuracy: 0.8949 - loss: 0.5321\nEpoch 47: val_loss did not improve from 0.36191\nEpoch 47 lr=1.531753e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 708ms/step - accuracy: 0.8949 - loss: 0.5321 - val_accuracy: 0.8736 - val_loss: 0.5659 - learning_rate: 1.5318e-04\nEpoch 48/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step - accuracy: 0.8949 - loss: 0.5441\nEpoch 48: val_loss did not improve from 0.36191\nEpoch 48 lr=1.468926e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 714ms/step - accuracy: 0.8949 - loss: 0.5441 - val_accuracy: 0.9336 - val_loss: 0.3675 - learning_rate: 1.4689e-04\nEpoch 49/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579ms/step - accuracy: 0.9108 - loss: 0.5205\nEpoch 49: val_loss improved from 0.36191 to 0.35900, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 49 lr=1.406153e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 718ms/step - accuracy: 0.9108 - loss: 0.5206 - val_accuracy: 0.9384 - val_loss: 0.3590 - learning_rate: 1.4062e-04\nEpoch 50/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step - accuracy: 0.8981 - loss: 0.5333\nEpoch 50: val_loss improved from 0.35900 to 0.35792, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 50 lr=1.343545e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 703ms/step - accuracy: 0.8981 - loss: 0.5332 - val_accuracy: 0.9352 - val_loss: 0.3579 - learning_rate: 1.3435e-04\nEpoch 51/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571ms/step - accuracy: 0.9057 - loss: 0.5407\nEpoch 51: val_loss improved from 0.35792 to 0.35169, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 51 lr=1.281211e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 710ms/step - accuracy: 0.9057 - loss: 0.5406 - val_accuracy: 0.9415 - val_loss: 0.3517 - learning_rate: 1.2812e-04\nEpoch 52/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560ms/step - accuracy: 0.8998 - loss: 0.5069\nEpoch 52: val_loss did not improve from 0.35169\nEpoch 52 lr=1.219262e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 680ms/step - accuracy: 0.8998 - loss: 0.5070 - val_accuracy: 0.9242 - val_loss: 0.3889 - learning_rate: 1.2193e-04\nEpoch 53/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step - accuracy: 0.9200 - loss: 0.4944\nEpoch 53: val_loss did not improve from 0.35169\nEpoch 53 lr=1.157804e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 700ms/step - accuracy: 0.9200 - loss: 0.4944 - val_accuracy: 0.9400 - val_loss: 0.3697 - learning_rate: 1.1578e-04\nEpoch 54/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - accuracy: 0.9062 - loss: 0.5057\nEpoch 54: val_loss did not improve from 0.35169\nEpoch 54 lr=1.096947e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 700ms/step - accuracy: 0.9062 - loss: 0.5058 - val_accuracy: 0.9273 - val_loss: 0.3844 - learning_rate: 1.0969e-04\nEpoch 55/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567ms/step - accuracy: 0.9088 - loss: 0.5011\nEpoch 55: val_loss did not improve from 0.35169\nEpoch 55 lr=1.036798e-04\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 694ms/step - accuracy: 0.9089 - loss: 0.5010 - val_accuracy: 0.9258 - val_loss: 0.3797 - learning_rate: 1.0368e-04\nEpoch 56/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604ms/step - accuracy: 0.9140 - loss: 0.4985\nEpoch 56: val_loss did not improve from 0.35169\nEpoch 56 lr=9.774603e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 728ms/step - accuracy: 0.9140 - loss: 0.4985 - val_accuracy: 0.9336 - val_loss: 0.3804 - learning_rate: 9.7746e-05\nEpoch 57/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576ms/step - accuracy: 0.9210 - loss: 0.4896\nEpoch 57: val_loss improved from 0.35169 to 0.34319, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 57 lr=9.190397e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 717ms/step - accuracy: 0.9210 - loss: 0.4896 - val_accuracy: 0.9479 - val_loss: 0.3432 - learning_rate: 9.1904e-05\nEpoch 58/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step - accuracy: 0.9197 - loss: 0.5023\nEpoch 58: val_loss did not improve from 0.34319\nEpoch 58 lr=8.616384e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 694ms/step - accuracy: 0.9197 - loss: 0.5023 - val_accuracy: 0.9431 - val_loss: 0.3458 - learning_rate: 8.6164e-05\nEpoch 59/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step - accuracy: 0.9263 - loss: 0.4995\nEpoch 59: val_loss did not improve from 0.34319\nEpoch 59 lr=8.053570e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 688ms/step - accuracy: 0.9263 - loss: 0.4995 - val_accuracy: 0.9463 - val_loss: 0.3445 - learning_rate: 8.0536e-05\nEpoch 60/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - accuracy: 0.9129 - loss: 0.5020\nEpoch 60: val_loss did not improve from 0.34319\nEpoch 60 lr=7.502941e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 695ms/step - accuracy: 0.9129 - loss: 0.5020 - val_accuracy: 0.9463 - val_loss: 0.3444 - learning_rate: 7.5029e-05\nEpoch 61/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566ms/step - accuracy: 0.9189 - loss: 0.4694\nEpoch 61: val_loss did not improve from 0.34319\nEpoch 61 lr=6.965466e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 689ms/step - accuracy: 0.9189 - loss: 0.4695 - val_accuracy: 0.9384 - val_loss: 0.3513 - learning_rate: 6.9655e-05\nEpoch 62/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - accuracy: 0.9234 - loss: 0.4786\nEpoch 62: val_loss did not improve from 0.34319\nEpoch 62 lr=6.442086e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 699ms/step - accuracy: 0.9234 - loss: 0.4786 - val_accuracy: 0.9368 - val_loss: 0.3529 - learning_rate: 6.4421e-05\nEpoch 63/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step - accuracy: 0.9292 - loss: 0.4790\nEpoch 63: val_loss improved from 0.34319 to 0.32346, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 63 lr=5.933719e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 694ms/step - accuracy: 0.9291 - loss: 0.4791 - val_accuracy: 0.9558 - val_loss: 0.3235 - learning_rate: 5.9337e-05\nEpoch 64/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - accuracy: 0.9267 - loss: 0.4763\nEpoch 64: val_loss did not improve from 0.32346\nEpoch 64 lr=5.441257e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 693ms/step - accuracy: 0.9267 - loss: 0.4763 - val_accuracy: 0.9463 - val_loss: 0.3369 - learning_rate: 5.4413e-05\nEpoch 65/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560ms/step - accuracy: 0.9204 - loss: 0.4952\nEpoch 65: val_loss improved from 0.32346 to 0.31782, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 65 lr=4.965565e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 693ms/step - accuracy: 0.9204 - loss: 0.4951 - val_accuracy: 0.9558 - val_loss: 0.3178 - learning_rate: 4.9656e-05\nEpoch 66/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575ms/step - accuracy: 0.9123 - loss: 0.4889\nEpoch 66: val_loss did not improve from 0.31782\nEpoch 66 lr=4.507477e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 704ms/step - accuracy: 0.9123 - loss: 0.4889 - val_accuracy: 0.9494 - val_loss: 0.3338 - learning_rate: 4.5075e-05\nEpoch 67/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step - accuracy: 0.9219 - loss: 0.4765\nEpoch 67: val_loss did not improve from 0.31782\nEpoch 67 lr=4.067796e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 700ms/step - accuracy: 0.9219 - loss: 0.4765 - val_accuracy: 0.9526 - val_loss: 0.3331 - learning_rate: 4.0678e-05\nEpoch 68/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.9235 - loss: 0.4785\nEpoch 68: val_loss did not improve from 0.31782\nEpoch 68 lr=3.647294e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 698ms/step - accuracy: 0.9235 - loss: 0.4785 - val_accuracy: 0.9621 - val_loss: 0.3216 - learning_rate: 3.6473e-05\nEpoch 69/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - accuracy: 0.9263 - loss: 0.4613\nEpoch 69: val_loss improved from 0.31782 to 0.31706, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 69 lr=3.246708e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 710ms/step - accuracy: 0.9263 - loss: 0.4613 - val_accuracy: 0.9589 - val_loss: 0.3171 - learning_rate: 3.2467e-05\nEpoch 70/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.9255 - loss: 0.4703\nEpoch 70: val_loss did not improve from 0.31706\nEpoch 70 lr=2.866742e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 692ms/step - accuracy: 0.9256 - loss: 0.4703 - val_accuracy: 0.9463 - val_loss: 0.3397 - learning_rate: 2.8667e-05\nEpoch 71/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step - accuracy: 0.9294 - loss: 0.4789\nEpoch 71: val_loss did not improve from 0.31706\nEpoch 71 lr=2.508061e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 699ms/step - accuracy: 0.9294 - loss: 0.4789 - val_accuracy: 0.9558 - val_loss: 0.3207 - learning_rate: 2.5081e-05\nEpoch 72/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565ms/step - accuracy: 0.9225 - loss: 0.4863\nEpoch 72: val_loss did not improve from 0.31706\nEpoch 72 lr=2.171296e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 686ms/step - accuracy: 0.9225 - loss: 0.4862 - val_accuracy: 0.9479 - val_loss: 0.3329 - learning_rate: 2.1713e-05\nEpoch 73/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9147 - loss: 0.4847\nEpoch 73: val_loss improved from 0.31706 to 0.31586, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 73 lr=1.857036e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 738ms/step - accuracy: 0.9148 - loss: 0.4846 - val_accuracy: 0.9558 - val_loss: 0.3159 - learning_rate: 1.8570e-05\nEpoch 74/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9324 - loss: 0.4724\nEpoch 74: val_loss did not improve from 0.31586\nEpoch 74 lr=1.565834e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 726ms/step - accuracy: 0.9324 - loss: 0.4725 - val_accuracy: 0.9573 - val_loss: 0.3225 - learning_rate: 1.5658e-05\nEpoch 75/75\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613ms/step - accuracy: 0.9376 - loss: 0.4687\nEpoch 75: val_loss improved from 0.31586 to 0.30644, saving model to /kaggle/working/artifacts/best_model.h5\nEpoch 75 lr=1.298200e-05\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 756ms/step - accuracy: 0.9375 - loss: 0.4687 - val_accuracy: 0.9652 - val_loss: 0.3064 - learning_rate: 1.2982e-05\nRestoring model weights from the end of the best epoch: 75.\nSaved final model to: /kaggle/working/artifacts/efnb4_se_final.h5\n\nTTA TEST Accuracy: 96.05%\n\n                      precision    recall  f1-score   support\n\n            cataract     0.9806    0.9744    0.9775       156\ndiabetic_retinopathy     1.0000    1.0000    1.0000       165\n            glaucoma     0.9521    0.9205    0.9360       151\n              normal     0.9102    0.9441    0.9268       161\n\n            accuracy                         0.9605       633\n           macro avg     0.9607    0.9597    0.9601       633\n        weighted avg     0.9609    0.9605    0.9606       633\n\nConfusion Matrix:\n [[152   0   1   3]\n [  0 165   0   0]\n [  0   0 139  12]\n [  3   0   6 152]]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Duplicate checks: exact (hash) and perceptual (average hash)\nimport os, hashlib\nfrom pathlib import Path\nfrom collections import defaultdict\nimport numpy as np\nfrom PIL import Image\n\n# set paths (these variables should exist from your earlier code)\n# If you used different variables, update them here:\ntry:\n    all_filepaths, all_labels, classes = load_filepaths_labels(DATA_DIR)\nexcept Exception as e:\n    # fallback: find classes automatically if earlier function not loaded\n    root = Path(DATA_DIR)\n    class_dirs = sorted([d for d in root.iterdir() if d.is_dir()])\n    classes = [p.name for p in class_dirs]\n    all_filepaths = []\n    all_labels = []\n    for i, p in enumerate(class_dirs):\n        for f in p.glob(\"*\"):\n            if f.suffix.lower() in (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\"):\n                all_filepaths.append(str(f))\n                all_labels.append(i)\n\n# if your train/test splits are named train_paths/test_paths, use them;\n# otherwise recreate a simple stratified split for the check:\nfrom sklearn.model_selection import train_test_split\ntrain_paths, temp_paths, train_labels, temp_labels = train_test_split(\n    all_filepaths, all_labels, test_size=0.30, random_state=42, stratify=all_labels)\nval_paths, test_paths, val_labels, test_labels = train_test_split(\n    temp_paths, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels)\n\nprint(f\"Using sets sizes — train: {len(train_paths)}, val: {len(val_paths)}, test: {len(test_paths)}\")\n\n# 1) Exact duplicate check via MD5\ndef file_md5(path, block_size=2**20):\n    h = hashlib.md5()\n    with open(path, \"rb\") as f:\n        while True:\n            chunk = f.read(block_size)\n            if not chunk:\n                break\n            h.update(chunk)\n    return h.hexdigest()\n\ndef find_exact_duplicates(setA, setB):\n    md5_to_path_A = {}\n    for p in setA:\n        try:\n            md5_to_path_A[file_md5(p)] = p\n        except Exception:\n            pass\n    dups = []\n    for p in setB:\n        try:\n            m = file_md5(p)\n            if m in md5_to_path_A:\n                dups.append((md5_to_path_A[m], p))\n        except Exception:\n            pass\n    return dups\n\nexact_dups = find_exact_duplicates(train_paths, test_paths)\nprint(\"Exact duplicates between train and test:\", len(exact_dups))\nif exact_dups:\n    for a,b in exact_dups[:10]:\n        print(\"  \", a, \"<->\", b)\n\n# 2) Perceptual duplicates via a simple average-hash (fast)\n#    (works reasonably well for detecting resized/contrast-changed same images)\ndef average_hash(image_path, hash_size=16):\n    try:\n        img = Image.open(image_path).convert(\"L\").resize((hash_size, hash_size), Image.BILINEAR)\n        arr = np.asarray(img, dtype=np.float32)\n        avg = arr.mean()\n        diff = arr > avg\n        # return bitstring as integer tuple\n        return tuple(diff.reshape(-1).astype(int))\n    except Exception:\n        return None\n\ndef hamming_distance(h1, h2):\n    if h1 is None or h2 is None: return 999\n    return sum(a!=b for a,b in zip(h1,h2))\n\n# build hashes for train and test (can take some seconds)\nprint(\"Computing perceptual hashes (avg-hash) for train/test...\")\ntrain_hashes = {p: average_hash(p) for p in train_paths}\ntest_hashes  = {p: average_hash(p) for p in test_paths}\n\n# find near-duplicates with small Hamming distance (threshold 10 is conservative for 16x16)\nthreshold = 10\nnear_dups = []\nfor tp, th in train_hashes.items():\n    if th is None: continue\n    for qp, qh in test_hashes.items():\n        if qh is None: continue\n        d = hamming_distance(th, qh)\n        if d <= threshold:\n            near_dups.append((tp, qp, d))\n# Sort by distance and show top 10\nnear_dups = sorted(near_dups, key=lambda x: x[2])\nprint(\"Perceptual near-duplicates between train and test (<= threshold):\", len(near_dups))\nif near_dups:\n    for a,b,d in near_dups[:10]:\n        print(f\"  dist={d}: {a} <-> {b}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T11:22:03.109176Z","iopub.execute_input":"2025-10-02T11:22:03.109457Z","iopub.status.idle":"2025-10-02T11:23:47.573891Z","shell.execute_reply.started":"2025-10-02T11:22:03.109435Z","shell.execute_reply":"2025-10-02T11:23:47.573095Z"}},"outputs":[{"name":"stdout","text":"Using sets sizes — train: 2951, val: 633, test: 633\nExact duplicates between train and test: 0\nComputing perceptual hashes (avg-hash) for train/test...\nPerceptual near-duplicates between train and test (<= threshold): 36512\n  dist=0: /kaggle/input/eye-diseases-classification/dataset/cataract/cataract_060.png <-> /kaggle/input/eye-diseases-classification/dataset/cataract/cataract_064.png\n  dist=0: /kaggle/input/eye-diseases-classification/dataset/cataract/cataract_060.png <-> /kaggle/input/eye-diseases-classification/dataset/glaucoma/Glaucoma_084.png\n  dist=0: /kaggle/input/eye-diseases-classification/dataset/cataract/cataract_060.png <-> /kaggle/input/eye-diseases-classification/dataset/cataract/cataract_024.png\n  dist=0: /kaggle/input/eye-diseases-classification/dataset/cataract/cataract_060.png <-> /kaggle/input/eye-diseases-classification/dataset/glaucoma/_387_8614768.jpg\n  dist=0: /kaggle/input/eye-diseases-classification/dataset/cataract/cataract_080.png <-> /kaggle/input/eye-diseases-classification/dataset/cataract/cataract_064.png\n  dist=0: /kaggle/input/eye-diseases-classification/dataset/cataract/cataract_080.png <-> /kaggle/input/eye-diseases-classification/dataset/glaucoma/Glaucoma_084.png\n  dist=0: /kaggle/input/eye-diseases-classification/dataset/cataract/cataract_080.png <-> /kaggle/input/eye-diseases-classification/dataset/cataract/cataract_024.png\n  dist=0: /kaggle/input/eye-diseases-classification/dataset/cataract/cataract_080.png <-> /kaggle/input/eye-diseases-classification/dataset/glaucoma/_387_8614768.jpg\n  dist=0: /kaggle/input/eye-diseases-classification/dataset/cataract/_172_1350351.jpg <-> /kaggle/input/eye-diseases-classification/dataset/normal/2426_left.jpg\n  dist=0: /kaggle/input/eye-diseases-classification/dataset/normal/3029_right.jpg <-> /kaggle/input/eye-diseases-classification/dataset/cataract/_157_8093661.jpg\n","output_type":"stream"}],"execution_count":2}]}